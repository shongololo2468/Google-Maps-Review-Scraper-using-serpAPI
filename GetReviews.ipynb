{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMI6QxdJEIWVhwSsQKHnnhU"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oTWO0R4-6Ex"
      },
      "outputs": [],
      "source": [
        "#packages\n",
        "!pip install -q serpapi\n",
        "!pip install -q google-search-results\n",
        "\n",
        "#imports\n",
        "from serpapi import GoogleSearch\n",
        "import pandas as pd\n",
        "import pprint\n",
        "import json\n",
        "\n",
        "#set serpAPI key\n",
        "apikey = \"insert api key\"\n",
        "\n",
        "#ITERATE THROUGH FACILITIES\n",
        "#read place names and locations\n",
        "place_data = pd.read_csv('insert directory path')\n",
        "\n",
        "#remove places without coordinates(requirement for review extraction)\n",
        "place_data.dropna(subset=['coordinates'], inplace=True)\n",
        "\n",
        "#retrieve place name\n",
        "place_data['OU5name'] = place_data['OU5name'].apply(lambda x: x[3:])\n",
        "\n",
        "#declare for output\n",
        "All_data_output = []\n",
        "\n",
        "#LOOP THROUGH ALL FACILITIES\n",
        "for facility in place_data.iterrows():\n",
        "  #set variables\n",
        "  place_name = str(facility[1]['OU5name'])\n",
        "  place_latitude = str(facility[1]['latitude'])\n",
        "  place_longitude = str(facility[1]['longitude'])\n",
        "  zoom = \"17z\"\n",
        "  location = \"@\" + place_latitude + \",\" + place_longitude + \",\" + zoom\n",
        "  #FIND PLACE_IDs FOR FIRST SEARCH RESULT\n",
        "  #set search parameters\n",
        "  params = {\n",
        "    \"engine\": \"google_maps\",\n",
        "    \"q\": place_name,\n",
        "    \"ll\": location,\n",
        "    \"type\": \"search\",\n",
        "    \"api_key\": apikey\n",
        "  }\n",
        "\n",
        "  #perform search\n",
        "  search = GoogleSearch(params)\n",
        "  results = search.get_dict()\n",
        "\n",
        "  #Find place_ID (diff between place and local results)\n",
        "  if 'place_results' in results:\n",
        "    place_ID = results[\"place_results\"][\"place_id\"]\n",
        "\n",
        "  else:\n",
        "    place_ID = results[\"local_results\"][0][\"place_id\"]\n",
        "\n",
        "  #FIND REVIEWS OF FIRST PAGE\n",
        "\n",
        "  #set parameters\n",
        "  params = {\n",
        "    \"engine\": \"google_maps_reviews\",\n",
        "    \"place_id\": place_ID,\n",
        "    \"api_key\": apikey\n",
        "  }\n",
        "\n",
        "  #perform search\n",
        "  search = GoogleSearch(params)\n",
        "  results = search.get_dict()\n",
        "\n",
        "  #retrieve place information (used in export)\n",
        "  place_info = results[\"place_info\"]\n",
        "  #add place info from dataset\n",
        "  place_info["latitude"] = place_latitude\n",
        "  place_info["longitude"] = place_longitude\n",
        "    if facility[1]['OrgUnitRuralUrban']:\n",
        "      urban_rural = str(facility[1]['OrgUnitRuralUrban'])\n",
        "      place_info["urban/rural"] = urban_rural\n",
        "\n",
        "  #retrieve reviews page 1\n",
        "  reviews_filtered = []\n",
        "\n",
        "  #filter only required review data\n",
        "  if 'reviews' in results:\n",
        "    reviews1 = results[\"reviews\"]\n",
        "    for review in reviews1:\n",
        "        if 'extracted_snippet' in review:\n",
        "          paragraph = review['extracted_snippet']['original']\n",
        "        else:\n",
        "          paragraph = \"No Review Text\"\n",
        "        if 'iso_date' in review:\n",
        "          date = review['iso_date']\n",
        "        else:\n",
        "          date = \"No Date\"\n",
        "        if 'rating' in review:\n",
        "          rating = review['rating']\n",
        "        else:\n",
        "          rating = \"No Rating\"\n",
        "\n",
        "        review_info = {'rating': rating, 'date': date, 'paragraph': paragraph}\n",
        "        reviews_filtered.append(review_info)\n",
        "  else:\n",
        "    reviews_filtered = []\n",
        "\n",
        "\n",
        "  #set next page token\n",
        "  if 'serpapi_pagination' in results:\n",
        "    next_page_token = results[\"serpapi_pagination\"][\"next_page_token\"]\n",
        "  else:\n",
        "    next_page_token = 0\n",
        "\n",
        "  #GET REVIEWS FROM PAGE 2 ONWARD (MAX 100)\n",
        "\n",
        "  if next_page_token == 0 or not reviews_filtered:\n",
        "    print(\"no more reviews\")\n",
        "  else:\n",
        "    for i in range(9):\n",
        "      if next_page_token == 0:\n",
        "        print(\"no more reviews\")\n",
        "        break\n",
        "      else:\n",
        "        #set parameters\n",
        "        params = {\n",
        "          \"engine\": \"google_maps_reviews\",\n",
        "          \"place_id\": place_ID,\n",
        "          \"next_page_token\": next_page_token,\n",
        "          \"api_key\": apikey\n",
        "        }\n",
        "\n",
        "        #perform search\n",
        "        search = GoogleSearch(params)\n",
        "        results = search.get_dict()\n",
        "\n",
        "        #filter only required review data\n",
        "        if 'reviews' in results:\n",
        "          reviews1 = results[\"reviews\"]\n",
        "          for review in reviews1:\n",
        "              if 'extracted_snippet' in review:\n",
        "                paragraph = review['extracted_snippet']['original']\n",
        "              else:\n",
        "                paragraph = \"No Review Text\"\n",
        "              if 'iso_date' in review:\n",
        "                date = review['iso_date']\n",
        "              else:\n",
        "                date = \"No Date\"\n",
        "              if 'rating' in review:\n",
        "                rating = review['rating']\n",
        "              else:\n",
        "                rating = \"No Rating\"\n",
        "\n",
        "              review_info = {'rating': rating, 'date': date, 'paragraph': paragraph}\n",
        "              reviews_filtered.append(review_info)\n",
        "\n",
        "        #set next page token\n",
        "        if 'serpapi_pagination' in results:\n",
        "          next_page_token = results[\"serpapi_pagination\"][\"next_page_token\"]\n",
        "        else:\n",
        "          next_page_token = 0\n",
        "\n",
        "\n",
        "\n",
        "  #CREATE NEAT OUTPUT FOR EACH FACILITY\n",
        "  current_facility_output = {\n",
        "      'name': place_info['title'],\n",
        "    'place_info': place_info,\n",
        "    'reviews': reviews_filtered\n",
        "  }\n",
        "  All_data_output.append(current_facility_output)\n",
        "\n",
        "\n",
        "#WRITE TO JSON FILE\n",
        "# Specify the filename for the JSON file\n",
        "filename = 'reviews.json'\n",
        "\n",
        "# Write combined_data to the JSON file (use 'a' instead of 'w' for appending rather than overwriting)\n",
        "with open(filename, 'w') as json_file:\n",
        "    json.dump(All_data_output, json_file, indent=4)"
      ]
    }
  ]
}
